# Phase 6 Context: Real-world problem with card metrics computation

## Problem observed

When a user asked Claude (with kaiten-mcp connected) to compute Kanban metrics for space 688824,
Claude generated a 400+ line Python script at `/tmp/compute_metrics_688824.py` and ran it directly
on the host machine. The script:

1. Made sequential API calls with 0.3s sleep between each
2. Fetched 539 cards (active + archived) with pagination (limit=100)
3. Then fetched location-history for EACH of the 539 cards individually
4. Total runtime: **~42 minutes**

## Key numbers

- 539 unique cards in space
- 539 sequential location-history requests (the bottleneck)
- Rate limit sleep: 0.3s per request -> 539 * 0.3s = ~162s just sleeping
- Actual time: ~42 minutes (includes network latency, retries, processing)
- Output: 18KB JSON with metrics

## Problems identified

1. **Script created outside MCP directory** - written to `/tmp/compute_metrics_688824.py`
2. **No MCP tools used** - Claude bypassed MCP entirely, wrote raw urllib code
3. **Sequential API calls** - 539 location histories fetched one by one
4. **API token hardcoded in script** - security issue
5. **No caching** - if run again, fetches everything from scratch
6. **No progress feedback through MCP** - user sees nothing until script finishes
7. **Monolithic approach** - single giant script instead of composable MCP tools

## What the script computed (for reference)

- System Lead Time (SLT): median 3.9d, mean 7.5d, P85 14.4d (172 cards)
- Cycle Time: median 1.8d, mean 6.0d, P85 14.2d (129 cards)
- Throughput: ~65 cards/month, 198 over last 3 months
- Bug Leakage: ~22 bugs/month (target was 4/month)
- MTTR Expedite: 1.0d, Standard: 5.1d
- Due Date on-time: 19% (4/21)
- WIP: 65 cards (53 stuck in "Разработка завершена")

## What Phase 6 should solve

1. **Auto-pagination tool** - `kaiten_list_all_cards(space_id, ...)` that transparently
   fetches all pages and returns combined results
2. **Batch location history** - fetch histories in parallel (asyncio.gather) respecting
   rate limit of 4.5 req/s, not 0.3s sequential sleep
3. **Export to file** - `kaiten_export_cards(space_id, output_path)` saves to file
   instead of returning huge JSON through MCP
4. **Caching layer** - store fetched cards locally so repeated queries don't re-fetch
5. **Skills guidance** - teach Claude to use MCP tools instead of writing raw scripts
6. **Progress indication** - for long operations, provide intermediate status
7. **Parallel fetching** - use asyncio.gather with semaphore for rate limiting

## Rate limit math

- Kaiten rate limit: ~4.5 req/s
- With asyncio.Semaphore(4): 539 requests / 4 concurrent = ~135 batches
- At 4.5 req/s effective: 539 / 4.5 = ~120 seconds = **2 minutes** (vs 42 min current)
- 21x speedup just from parallelization

## Board structure discovered (space 688824)

- Board 1472857 "Бэклог разработки": col 5110180 "Очередь задач" (subcols: Бэклог, Готово для анализа)
- Board 1472858 "Разработка": cols Анализ, Разработка, PR to Stage, Merged to Stage, PR to Master, Merged to Master
- Board 1472860 "Разработка завершена": col 5110186
- Board 1340458 "Content/Анонс": cols Очередь, В работе, Готово
- Board 1528971 "Архитектурный комитет"
- Board 1538357 "Таски" (subtask decomposition)
- Lanes: Срочные, К Дате, Обычные, Фоновые (4 service classes)
